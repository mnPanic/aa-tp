{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be80f25-ad24-4346-8386-90df77604ddf",
   "metadata": {},
   "source": [
    "## Content sopa\n",
    "\n",
    "Tomamos los usuarios que tengan x+y ratings de peliculas.\n",
    "Removemos las x peliculas de sus ratings, y pedimos las recomendaciones para las y peliculas.\\\n",
    "Del total de recomendaciones nos quedamos con el TOP z, ordenando por aparicion, y el promedio del cosine_similarity.\\\n",
    "Calculamos recall y precision, variamos x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "076e4c1e-f215-4cfa-98aa-979870933ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db24e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import result_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce10f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"dataset\"\n",
    "movies = pd.read_csv(f\"{BASE_PATH}/movies_metadata.csv\", low_memory=False)\n",
    "credits = pd.read_csv(f'{BASE_PATH}/credits.csv')\n",
    "keywords = pd.read_csv(f'{BASE_PATH}/keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c92b051-cdb7-4c42-8ff5-a73de0cf2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with bad IDs.\n",
    "movies = movies.drop([19730, 29503, 35587])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65085949-1273-4d4c-886e-228ee0ebc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert IDs to int. Required for merging\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "movies['id'] = movies['id'].astype('int')\n",
    "\n",
    "# Merge keywords and credits into your main metadata dataframe\n",
    "movies = movies.merge(credits, on='id')\n",
    "movies = movies.merge(keywords, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe91022a-bbe7-4b10-a9a4-0ff9860b141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 46628, after: 45432, diff: 1196\n"
     ]
    }
   ],
   "source": [
    "# Sacamos las películas duplicadas, algunas como id 69234 aparecen dos veces\n",
    "len_before = len(movies)\n",
    "movies = movies.drop_duplicates(subset=[\"id\"]).reset_index()\n",
    "print(f\"before: {len_before}, after: {len(movies)}, diff: {len_before - len(movies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e9bb48-51c6-40c9-8f19-df72eb4b545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the stringified features into their corresponding python objects\n",
    "from ast import literal_eval\n",
    "\n",
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    movies[feature] = movies[feature].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96502829-500e-4b72-af2b-0f6cfb993ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3d4463-7bdd-4763-b14b-a772b26d6bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cast</th>\n",
       "      <th>director</th>\n",
       "      <th>keywords</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[Tom Hanks, Tim Allen, Don Rickles]</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>[jealousy, toy, boy]</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[Robin Williams, Jonathan Hyde, Kirsten Dunst]</td>\n",
       "      <td>Joe Johnston</td>\n",
       "      <td>[board game, disappearance, based on children'...</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[Walter Matthau, Jack Lemmon, Ann-Margret]</td>\n",
       "      <td>Howard Deutch</td>\n",
       "      <td>[fishing, best friend, duringcreditsstinger]</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title                                            cast  \\\n",
       "0         Toy Story             [Tom Hanks, Tim Allen, Don Rickles]   \n",
       "1           Jumanji  [Robin Williams, Jonathan Hyde, Kirsten Dunst]   \n",
       "2  Grumpier Old Men      [Walter Matthau, Jack Lemmon, Ann-Margret]   \n",
       "\n",
       "        director                                           keywords  \\\n",
       "0  John Lasseter                               [jealousy, toy, boy]   \n",
       "1   Joe Johnston  [board game, disappearance, based on children'...   \n",
       "2  Howard Deutch       [fishing, best friend, duringcreditsstinger]   \n",
       "\n",
       "                         genres  \n",
       "0   [Animation, Comedy, Family]  \n",
       "1  [Adventure, Fantasy, Family]  \n",
       "2             [Romance, Comedy]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define new director, cast, genres and keywords features that are in a suitable form.\n",
    "movies['director'] = movies['crew'].apply(get_director)\n",
    "\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    movies[feature] = movies[feature].apply(get_list)\n",
    "# Print the new features of the first 3 films\n",
    "movies[['title', 'cast', 'director', 'keywords', 'genres']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc9c2c4-528f-49cb-af9c-dd6a01026a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all strings to lower case and strip names of spaces\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90cca629-0b4f-4573-bb01-54c928350d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean_data function to your features.\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    movies[feature] = movies[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724371ab-3559-4fa4-be39-6b4ff00a5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "# Create a new soup feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6923b12-26ca-4e17-af68-61f98865603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jealousy toy boy tomhanks timallen donrickles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boardgame disappearance basedonchildren'sbook ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                soup\n",
       "0  jealousy toy boy tomhanks timallen donrickles ...\n",
       "1  boardgame disappearance basedonchildren'sbook ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['soup'] = movies.apply(create_soup, axis=1)\n",
    "movies[['soup']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d93cc11-be0c-47be-a2dc-4df5b9e8a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(movies['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c5a8a2-85d0-42ee-a7c6-2edc0e3251d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45432, 73880)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6a17c08-67d7-4e13-883e-c7cda90ce0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d077c5fd-6614-47a6-a08c-a040c06d0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_shit_indices = pd.Series(movies.index, index=movies['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11bb5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_and_similarities(data, movie_id):\n",
    "    # Get the movie index from dataframe\n",
    "    idx = real_shit_indices[movie_id]\n",
    "    \n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for index, similarity in sim_scores:\n",
    "        title = data.iloc[index]['title']\n",
    "        tmdb_id = data.iloc[index]['id']\n",
    "        row = {'index':index, 'title':title, 'similarity':similarity, 'tmdbId': tmdb_id}\n",
    "        rows.append(row)\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    #return pd.DataFrame.from_records(rows)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b01aa17-0127-4245-adaa-c61c5b2696cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_ratings = pd.read_csv(f\"{BASE_PATH}/ratings.csv\", dtype={'userId': int, 'movieId': str, 'rating': float,'timestamp': int})\n",
    "id_links = pd.read_csv(f\"{BASE_PATH}/links.csv\", dtype={'movieId': str, 'imdbId': str, 'tmdbId': str})\n",
    "user_ratings = pd.merge(user_ratings, id_links, left_on='movieId', right_on='movieId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f888be46-4a10-474d-841c-c2e4aeb1fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = user_ratings.dropna(subset=[\"tmdbId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "823c000f-ac8e-4042-b060-9e4324af6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = user_ratings.astype({\"tmdbId\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1063ffc-6760-45b3-b0f4-280d88ec5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_with_titles(df: pd.DataFrame):\n",
    "    df_with_titles = pd.merge(df, movies[[\"id\", \"title\"]], left_on=\"tmdbId\", right_on=\"id\", how=\"left\")\n",
    "    return df_with_titles.drop('id', axis=1) # 1 = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7691b677-e11b-4c8f-9aa7-221df44f1866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ad3343beaf4d7cb1a2b68f6fc514ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=45432.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Precomputamos \n",
    "movie_ids = movies[\"id\"]\n",
    "recoms_by_movie = {}\n",
    "\n",
    "for movie_id in tqdm(movie_ids):\n",
    "    recoms_by_movie[movie_id] = get_recommendations_and_similarities(movies, movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "463655cc-0d71-49ec-b26f-205876002674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import result_io\n",
    "import json\n",
    "\n",
    "def write_recoms_by_movie(recoms: dict):\n",
    "    with open(\"results/recoms-by-movie-sopa.json\", 'w') as f:\n",
    "        json_str = json.dumps(recoms)\n",
    "        f.write(json_str)\n",
    "\n",
    "#json_str = json.dumps(recoms_by_movie)\n",
    "#write_recoms_by_movie(recoms_by_movie)\n",
    "#recoms_by_movie = result_io.read_recoms_by_movie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c006d-ca23-4750-a4b8-92c522ec2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestep(start: float, name: str) -> float:\n",
    "    now = time.time()\n",
    "    print(f\"{name}: {now - start}\")\n",
    "    return now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0886d697-7723-4f5c-b061-84c92217e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cached_recommendations_and_similarities(movie_id):\n",
    "    rows = recoms_by_movie[int(movie_id)]\n",
    "    return pd.DataFrame.from_records(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d252130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommendations(user, user_ratings_train=user_ratings):\n",
    "    # WARNING!\n",
    "    #\n",
    "    # La matriz de ratings no usa el mismo ID que la matriz movies_metadata\n",
    "    # En el archivo links se establece una relación entre el movieID de ratings y los IDs de TMBD e IMBD (que el primero parece ser el de movies_metadata)\n",
    "    movies_and_ratings = user_ratings_train[user_ratings_train['userId'] == user][['tmdbId','rating']]\n",
    "    out = pd.DataFrame(columns=['index', 'title', 'similarity', \"tmdbId\"])\n",
    "\n",
    "    for _, info in movies_and_ratings.iterrows():\n",
    "        # real shit indices se indexa con string, y estos son numeros i.e. '123', y movieId es un float, tonse '123.0' pincha\n",
    "        movieID = str(int(info.loc['tmdbId']))\n",
    "        rating = info.loc['rating']\n",
    "\n",
    "        recommendations = get_cached_recommendations_and_similarities(movieID)\n",
    "        \n",
    "        # Pesa la similaridad * rating, y la normaliza ( /5.0)\n",
    "        recommendations['similarity'] = recommendations['similarity'] * rating / 5.0\n",
    "\n",
    "        out = pd.concat([out,recommendations])\n",
    "        #out = out.append(recommendations, ignore_index=True)\n",
    "\n",
    "    out = out.groupby(['index','title', 'tmdbId'])\n",
    "\n",
    "    # TODO: tal vez hacer algo diferente de mean que premie que aparezca más de una vez.\n",
    "    out = out.agg({'similarity':'mean'}).rename(columns={'similarity':'mean_similarity'}).reset_index()\n",
    "    \n",
    "    out.sort_values(by='mean_similarity', ascending=False, inplace=True)\n",
    "    to_remove = pd.merge(movies_and_ratings, real_shit_indices.to_frame(), left_on='tmdbId', right_on='id', how='left')\n",
    "    \n",
    "    # Dado que le mergeamos la serie, queda la columna referenciable con el int 0 que son\n",
    "    # la lista de index del dataframe de movies\n",
    "    to_remove = to_remove[0].to_list()\n",
    "\n",
    "    out = out[~out['index'].isin(to_remove)][0:10]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95dbd309-517a-477a-8728-60e16a05bc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>mean_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2279</td>\n",
       "      <td>Star Trek: Insurrection</td>\n",
       "      <td>200</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5805</td>\n",
       "      <td>Star Trek: Nemesis</td>\n",
       "      <td>201</td>\n",
       "      <td>0.639010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>Star Trek: Generations</td>\n",
       "      <td>193</td>\n",
       "      <td>0.639010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1154</td>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>1891</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>42175</td>\n",
       "      <td>The Big Sick</td>\n",
       "      <td>416477</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>23456</td>\n",
       "      <td>Mission: Impossible - Rogue Nation</td>\n",
       "      <td>177677</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>442</td>\n",
       "      <td>The Favor</td>\n",
       "      <td>50463</td>\n",
       "      <td>0.478091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1323</td>\n",
       "      <td>Star Trek VI: The Undiscovered Country</td>\n",
       "      <td>174</td>\n",
       "      <td>0.456435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1324</td>\n",
       "      <td>Star Trek V: The Final Frontier</td>\n",
       "      <td>172</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2262</td>\n",
       "      <td>A View to a Kill</td>\n",
       "      <td>707</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                   title  tmdbId  mean_similarity\n",
       "26    2279                 Star Trek: Insurrection     200         0.750000\n",
       "54    5805                      Star Trek: Nemesis     201         0.639010\n",
       "5      324                  Star Trek: Generations     193         0.639010\n",
       "12    1154                 The Empire Strikes Back    1891         0.560000\n",
       "170  42175                            The Big Sick  416477         0.500000\n",
       "127  23456      Mission: Impossible - Rogue Nation  177677         0.480000\n",
       "7      442                               The Favor   50463         0.478091\n",
       "15    1323  Star Trek VI: The Undiscovered Country     174         0.456435\n",
       "16    1324         Star Trek V: The Final Frontier     172         0.416667\n",
       "25    2262                        A View to a Kill     707         0.400000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_recommendations(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e8d65bd-00b5-4b7f-a7c9-7719b4a652b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26010786"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_ratings_small = user_ratings[:len(user_ratings) // 2**6]\n",
    "user_ratings_small = user_ratings\n",
    "len(user_ratings_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d5d7653e-3eb3-44cf-8dfb-7b746bdf35a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 26010786, after filter: 25981578\n"
     ]
    }
   ],
   "source": [
    "# 1. Sacar películas para las que no tenemos metadata\n",
    "# hay algunas películas como \"253768\" que están en ratings pero no en movies.\n",
    "rated_movies = user_ratings_small[\"tmdbId\"]\n",
    "rated_movies_with_metadata = rated_movies[rated_movies.isin(movies[\"id\"])]\n",
    "metadata_filtered_user_ratings = user_ratings_small[user_ratings_small[\"tmdbId\"].isin(rated_movies_with_metadata)]\n",
    "\n",
    "print(f\"total: {len(user_ratings_small)}, after filter: {len(metadata_filtered_user_ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea02dca6-cfe5-40da-8f6a-d77bfc707405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 25981578, after filter: 25556150\n",
      "(diff = 425428)\n"
     ]
    }
   ],
   "source": [
    "# 2. Sacar los que tienen menos de 15\n",
    "user_rating_count = metadata_filtered_user_ratings.groupby([\"userId\"]).count()\n",
    "users_to_remove = user_rating_count[user_rating_count[\"movieId\"] < 15].reset_index()[\"userId\"]\n",
    "filtered_user_ratings = metadata_filtered_user_ratings[~metadata_filtered_user_ratings[\"userId\"].isin(users_to_remove)]\n",
    "\n",
    "print(f\"total: {len(metadata_filtered_user_ratings)}, after filter: {len(filtered_user_ratings)}\")\n",
    "print(f\"(diff = {len(metadata_filtered_user_ratings) - len(filtered_user_ratings)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bae8325b-67a7-4ac7-a212-6c321577f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(elems: list, chunks: int):\n",
    "    chunk_size = len(elems)//chunks\n",
    "    rem = len(elems)%chunks\n",
    "    chunks_split = [ elems[chunk_size*i:chunk_size*(i+1)] for i in range(0, chunks)]\n",
    "\n",
    "    # Agregamos el resto al último\n",
    "    chunks_split[chunks-1].extend(elems[len(elems) - rem:])\n",
    "\n",
    "    return chunks_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "873c3ebe-9f00-40aa-aa15-2a0689d5cf35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] start\n",
      "[1] start[2] start\n",
      "\n",
      "[3] start\n",
      "[4] start\n",
      "[5] start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb70c979201f46ceac529ee8ed15a24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #1'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c68ef0ae284798a4f146f775cacd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #2'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e6b90c68ec40a39315d894b79d8575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #0'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dadce6598f44947bcad9463765d3529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #3'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780ca421eceb4bc6a7349637cff22b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #4'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8919e08ff9f84f09978ded4ded10c323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #5'), FloatProgress(value=0.0, max=35413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[2] finish\n",
      "\n",
      "\n",
      "[0] finish\n",
      "[3] finish\n",
      "[5] finish\n",
      "[1] finish\n",
      "[4] finish\n",
      "Finished!\n",
      "CPU times: user 2min 41s, sys: 1min 20s, total: 4min 1s\n",
      "Wall time: 40min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3. Sacar 10 de cada uno para test\n",
    "\n",
    "from multiprocess import Process, Manager\n",
    "from typing import List\n",
    "# https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce\n",
    "\n",
    "def sample_test_ratings(procnum: int, return_dict, users: List[int]):\n",
    "    print(f\"[{procnum}] start\")\n",
    "    test = pd.DataFrame(columns=filtered_user_ratings.columns)\n",
    "\n",
    "    for user_id in tqdm(users, position=procnum, desc=f\" proc #{procnum}\"):\n",
    "        movies_of_user = filtered_user_ratings[filtered_user_ratings[\"userId\"] == user_id].sample(n=10)\n",
    "        test = pd.concat([test, movies_of_user])\n",
    "\n",
    "    return_dict[procnum] = test\n",
    "    print(f\"[{procnum}] finish\")\n",
    "\n",
    "user_ids = list(filtered_user_ratings[\"userId\"].unique())\n",
    "users_split = split_into_chunks(user_ids, 6)\n",
    "\n",
    "procs = []\n",
    "manager = Manager()\n",
    "return_dict = manager.dict()\n",
    "for i, chunk in enumerate(users_split):\n",
    "    p = Process(target=sample_test_ratings, args=(i, return_dict, chunk))\n",
    "    p.start()\n",
    "    procs.append(p)\n",
    "\n",
    "for p in procs:\n",
    "    p.join()\n",
    "\n",
    "test = pd.DataFrame(columns=filtered_user_ratings.columns)\n",
    "for return_value in return_dict.values():\n",
    "    test = pd.concat([test, return_value])\n",
    "    \n",
    "train = filtered_user_ratings.drop(test.index)\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f558633a-43c6-46cb-8a62-13a836ac98e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"dfs/content-sopa-train.csv\")\n",
    "test.to_csv(\"dfs/content-sopa-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7999b95d-419a-4474-ada2-56e1de9cab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"dfs/content-sopa-train.csv\", index_col=0, dtype={\"tmdbId\": int})\n",
    "test = pd.read_csv(\"dfs/content-sopa-test.csv\", index_col=0, dtype={\"tmdbId\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "336150a3-e998-43a3-bc20-bd4f3cb43b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No processed users\n",
      "Already processed 0/212468 users\n"
     ]
    }
   ],
   "source": [
    "# Remove users that were already processed\n",
    "import result_io\n",
    "processed_users = result_io.read_processed_users_for(result_io.NAME_CONTENT_SOPA)\n",
    "\n",
    "users = train[\"userId\"]\n",
    "users = users[~np.isin(users, processed_users)]\n",
    "users = list(users.unique())\n",
    "\n",
    "print(f\"Already processed {len(processed_users)}/{len(users) + len(processed_users)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90a43d30-02d6-46e8-b1f4-1f0bfa8b2f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]: start[0]: start\n",
      "\n",
      "[2]: start\n",
      "[3]: start\n",
      "[4]: start\n",
      "[5]: start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326af2b7bddb40429cc67aaadc98460f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #0'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d753fafc74284de8bf4fa351b99f42a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #2'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9296306a1e44f629293c07b945bb464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #1'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a6723980234a49be87ee41a799400d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #3'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7676231f5c874060a76ca4e48ca00ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #4'), FloatProgress(value=0.0, max=35411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be8864b7dab4411a582bf8259f19b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' proc #5'), FloatProgress(value=0.0, max=35413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5]: finish\n",
      "\n",
      "[2]: finish\n",
      "\n",
      "[4]: finish\n",
      "\n",
      "[3]: finish\n",
      "\n",
      "[0]: finish\n",
      "\n",
      "[1]: finish\n",
      "Finished!\n",
      "CPU times: user 2min 10s, sys: 1min 11s, total: 3min 22s\n",
      "Wall time: 1h 55min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from multiprocess import Process, Manager\n",
    "from typing import List\n",
    "# https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce\n",
    "\n",
    "def predict(i: int, users: List[int]):\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    print(f\"[{i}]: start\")\n",
    "    for user_id in tqdm(users, position=i, desc=f\" proc #{i}\"):\n",
    "        predicted_movies = list(get_user_recommendations(user_id, train)[\"tmdbId\"])\n",
    "        actual_movies = list(test[test[\"userId\"] == user_id][\"tmdbId\"])\n",
    "        \n",
    "        result_io.write_results_new_format(result_io.NAME_CONTENT_SOPA, user_id, predicted_movies, actual_movies)\n",
    "        \n",
    "    print(f\"[{i}]: finish\")\n",
    "\n",
    "users_split = split_into_chunks(users, 6)\n",
    "\n",
    "procs = []\n",
    "for i, chunk in enumerate(users_split):\n",
    "    p = Process(target=predict, args=(i, chunk))\n",
    "    p.start()\n",
    "    procs.append(p)\n",
    "\n",
    "for p in procs:\n",
    "    p.join()\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f2499a60-00c5-4241-b08b-2ac30880c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import result_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0db57ad9-7f94-41cc-81d8-eca1f83129eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011037699682730932, 0.011037699682730932)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import average_precision\n",
    "import recmetrics.metrics\n",
    "\n",
    "predicted, actual = read_results_new_format(result_io.NAME_CONTENT_SOPA)\n",
    "\n",
    "mark = recmetrics.metrics.mark(actual, predicted, k=10)\n",
    "mapk = average_precision.mapk(actual, predicted, k=10)\n",
    "mark, mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29190aa-3d89-4e04-9168-8f1843e21722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "def read_results_new_format(name: str) -> Tuple[List[List[str]], List[List[str]]]:\n",
    "    with open(result_io.filename(name), 'r') as f:\n",
    "        content = f.read()\n",
    "        lines = content.rstrip().split('\\n')\n",
    "        predicted = []\n",
    "        actual = []\n",
    "        \n",
    "        for line in lines:\n",
    "            l = line.split('|')\n",
    "            # user|predicted|actual\n",
    "            pred = result_io.parse_list(l[1])\n",
    "            act = result_io.parse_list(l[2])\n",
    "\n",
    "            predicted.append(pred)\n",
    "            actual.append(act)\n",
    "        \n",
    "        return predicted, actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ac466-84f8-46e0-a0af-4da85cde176d",
   "metadata": {},
   "source": [
    "## Corriendo para nuestros users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9cd403b-e1db-4f6a-8719-36e6f716222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(\"users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0dad1391-986f-4b1b-888c-f02889b99fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "\n",
    "user_id_manu = 300001\n",
    "user_id_elias = 300002\n",
    "user_id_mati = 300003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "05fef2f7-d5e3-40e7-af2f-7318af063ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0704/164608.363852:INFO:headless_shell.cc(660)] Written to file /var/folders/ww/8n507dkn503d0xnc7_dlmgy1lj2mm0/T/tmp_vyqwkg0/temp.png.\n"
     ]
    }
   ],
   "source": [
    "df = get_user_recommendations(user_id_elias, df_users)\n",
    "dfi.export(df, \"graficos/tests/content-sopa-elias.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "504b9ebb-29d6-4c81-a34b-ff9838b241f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0704/164610.723870:INFO:headless_shell.cc(660)] Written to file /var/folders/ww/8n507dkn503d0xnc7_dlmgy1lj2mm0/T/tmp2jkws8x5/temp.png.\n"
     ]
    }
   ],
   "source": [
    "df = get_user_recommendations(user_id_manu, df_users)\n",
    "dfi.export(df, \"graficos/tests/content-sopa-manu.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9ab39f7a-0b01-484e-b592-1b1865edcbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0704/164611.958676:INFO:headless_shell.cc(660)] Written to file /var/folders/ww/8n507dkn503d0xnc7_dlmgy1lj2mm0/T/tmpvunp2rcn/temp.png.\n"
     ]
    }
   ],
   "source": [
    "df = get_user_recommendations(user_id_mati, df_users)\n",
    "dfi.export(df, \"graficos/tests/content-sopa-mati.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6909f6b-69c1-471d-bf5a-7685e03409e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
